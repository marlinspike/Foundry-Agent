# ─────────────────────────────────────────────────────────────────────────────
#  Azure AI Foundry — required for the Orchestrator model and agent invocation
# ─────────────────────────────────────────────────────────────────────────────

# Your Foundry project endpoint
# Format: https://<your-hub>.services.ai.azure.com/api/projects/<your-project>
FOUNDRY_PROJECT_ENDPOINT=https://<your-hub>.services.ai.azure.com/api/projects/<your-project>
FOUNDRY_API_KEY=<your-foundry-api-key>
FOUNDRY_USE_KEY_AUTH=false

# The model deployment used by the Orchestrator agent for direct answers
# and intent routing.  gpt-4.1-mini is a good balance of quality and cost.
FOUNDRY_MODEL_DEPLOYMENT_NAME=<your-model-deployment-name>

# ─────────────────────────────────────────────────────────────────────────────
#  Existing Foundry agent names (must match exactly what's in your project)
# ─────────────────────────────────────────────────────────────────────────────
AF_AGENT_NAME=<your-af-agent-name>
NICEIFY_AGENT_NAME=<your-niceify-agent-name>

# ─────────────────────────────────────────────────────────────────────────────
#  Optional: Azure OpenAI (use instead of Foundry for direct answers)
#  Set MODEL_PROVIDER=azure_openai to activate.
# ─────────────────────────────────────────────────────────────────────────────
# MODEL_PROVIDER=foundry          # foundry | azure_openai | openai  (default: foundry)
MODEL_PROVIDER=azure_openai
# Format: https://<resource>.cognitiveservices.azure.com/ (base URL only, no path or query string)
AZURE_OPENAI_ENDPOINT=https://<your-resource>.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=<your-azure-openai-deployment-name>
AZURE_OPENAI_API_KEY=<your-azure-openai-api-key>

# ─────────────────────────────────────────────────────────────────────────────
#  Optional: OpenAI (public API)
#  Set MODEL_PROVIDER=openai to activate.
# ─────────────────────────────────────────────────────────────────────────────
# OPENAI_API_KEY=<your-openai-api-key>
# OPENAI_MODEL=gpt-4.1-mini

# ─────────────────────────────────────────────────────────────────────────────
#  Behaviour flags
# ─────────────────────────────────────────────────────────────────────────────
# Set to "true" to automatically pass every AF response through Niceify
# when negative sentiment is detected.
AUTO_NICEIFY=false

# How the orchestrator decides which agent to call.
#   keyword  (default) — fast, zero-cost matching against hard-coded keyword lists
#   model              — one extra LLM call per turn; handles synonyms and context
ROUTING_MODE=model
